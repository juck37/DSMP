---
title: "W3 Assignment"
author: CL
output: html_document
date: '2024-10-10'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## NYPD Shooting Incident Data (Historic) Analysis
Load the libraries

```{r library}
library(tidyverse)
library(lubridate)
library(ggplot2)
```

# Step 1: Import the NYPD Shooting Data

```{r data}
data <- "https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD"
nydata <- read_csv(data)
head(nydata)
```

# Step 2: DATA PREP - Keep the variables of interest

```{r keep}
nydata <- nydata %>%
  select(
  INCIDENT_KEY, OCCUR_DATE, OCCUR_TIME, STATISTICAL_MURDER_FLAG, LOCATION_DESC, 
  JURISDICTION_CODE
  )

head(nydata)
```  

# Step 3. TIDY the NYPD Shooting Data
I am interested in examining changes in the murder rate from shootings over time. To explore this, I converted the occur_date variable to Date format and extracted the corresponding year. Next, I calculated the number of murder cases per incident key, retaining only one row for each unique combination of incident_key and year.
```{r date}
nydata <- nydata %>%
  mutate(
  OCCUR_DATE = as.Date(OCCUR_DATE, format = "%m/%d/%Y"),
    year = year(OCCUR_DATE)
  )

murder_case <- nydata %>%
  group_by(INCIDENT_KEY, year) %>%
  summarise(murder = any(tolower(STATISTICAL_MURDER_FLAG) == "true")) %>%
  ungroup()

murder_case %>%
  summarise(total_murder=sum(murder))

murder_year <- murder_case %>%
  group_by(year) %>%
  summarise(
    total_shooting = n(), 
    total_murder = sum(murder),
    murder_rate = (total_murder/total_shooting)*100
  )

print(murder_year)
``` 

# Step 4. Plot trend of murder rate over time
The graph depicts the annual murder rate in NYPD shooting incidents over time, with the y-axis showing the percentage of shootings that resulted in fatalities and the x-axis displaying the years. Notable fluctuations are evident, with a significant drop occurring around 2014 (by 15.27%), marking the lowest point on the graph, followed by a rise in more recent years. This pattern suggests that the lethality of shooting incidents in New York City has varied considerably over time. This may be due to changes in law enforcement strategies, improvements or challenges in emergency medical response, or shifts in social or environmental conditions affecting gun violence. It is important to note that the graph represents the proportion of fatal shootings, not the total number of incidents, indicating that a lower murder rate doesn't necessarily mean fewer shootings overall, but rather a lower percentage of shootings resulting in deaths. 
```{r plot}
ggplot(murder_year, aes(x=year, y=murder_rate)) +
  geom_line() + 
  geom_point() + 
  labs(
    title = "Trend of Murder Rate in NYPD Shooting Cases",
    x = "Year", 
    y = "Murder Rate (%)"
  ) + 
  theme_minimal()
```

# Step 5. PREP for Statistical Modeling: Build on Step 3
Next, I explored whether the murder rate varies by jurisdiction within NYPD shooting incidents. The NYPD jurisdiction codes are categorized as 0 (Patrol), 1 (Transit), and 2 (Housing). To analyze this, I grouped the data by incident key and jurisdiction code, ensuring that each unique incident is counted only once. Specifically, if any row associated with an incident indicated a statistical murder, the entire incident was classified as a murder, regardless of the number of rows or additional details linked to that incident. 
```{r stat}
murder_jr <- nydata %>%
  group_by(INCIDENT_KEY, JURISDICTION_CODE) %>%
  summarise(murder_jr_code = any(tolower(STATISTICAL_MURDER_FLAG) == "true")) %>%
  ungroup()

head(murder_jr)
```

# Step 6. Conduct Logistic Regression Model
I fitted a logistic regression model to the data to examine whether the jurisdiction type is associated with the likelihood of shootings that contain statistical murder cases. 
```{r logit}
murder_jr <- murder_jr %>%
  mutate(JURISDICTION_CODE=as.factor(JURISDICTION_CODE))

logit <- glm(murder_jr_code ~ JURISDICTION_CODE, 
             data = murder_jr,
             family = binomial)

summary(logit)
```

# Step 7. Interpreting coefficients from the logistic regression
Logistic regression results indicate that the baseline coefficient for jurisdiction 0 (Patrol) is -1.394, with an odds ratio of 0.248. This means that the odds of a shooting resulting in murder in transit are roughly 24.8% compared to the odds of non-murder incidents. Compared to Patrol, the odds of a shooting resulting in a murder in Transit (jurisdiction code 1) are slightly lower by 9.5%, but this difference is not statistically significant. Conversely, such odds for jurisdiction 2 (Housing) are significantly lower by 24.4% compared to Patrol, indicating a substantially reduced likelihood of shootings resulting in murder in Housing.
```{r interpret}
coef_jr <- coef(logit)

odds <- exp(coef_jr)

logit_summary <- data.frame(
  Term = names(coef_jr),
  Coefficient = round(coef_jr, 3),
  Odds_Ratio = round(odds, 3)
)

print(logit_summary)
```

# Step 8. Visualizing Odds Ratios
The baseline category (=Patrol)'s odds ratio is 1 (=red line).The odds ratios for both transit and housing are less than that of the baseline category (=Patrol), suggesting that shootings in these jurisdictions--particularly in housing--have a lower likelihood of being statistical murder cases compared to the baseline jurisdiction (=Patrol).
```{r odds}
logit_vs <- logit_summary[-1, ]

logit_vs <- logit_vs %>%
  mutate(
    Term = case_when(
      Term == "JURISDICTION_CODE1" ~ "Transit",
      Term == "JURISDICTION_CODE2" ~ "Housing",
      TRUE ~ Term
    )
  )

ggplot(logit_vs, aes(x=Term, y=Odds_Ratio)) +
  geom_point() +
  geom_hline(yintercept = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Odds Ratios for Jurisdiction Types",
    x = "Jurisdiction Type", 
    y = "Odds Ratio \n(Statistical Murder vs. Non-statistical Murder)"
  ) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust=1))
```

# Step 9. Bias inspection
My initial plan was to analyze the murder rate by location; however, this variable contains a substantial amount of missing data, as shown below. To mitigate potential bias from these missing data points, I revised my approach to focus on the variation in murder rate by jurisdiction code, which has only two missing cases (0.007%). 
```{r bias}
missing_nydata <- nydata %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Missing_Count")


missing_nydata <- missing_nydata %>%
  mutate(Percentage_missing= (Missing_Count/nrow(nydata))*100)
print(missing_nydata)
```

# Step 10. Session Information
``` {r session}
sessionInfo()
```